{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5lOQ0oK5bgB"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def extract_features(audio_file, sr=22050, n_mfcc=13):\n",
        "    \"\"\"\n",
        "    Extract audio features from an audio file.\n",
        "\n",
        "    Parameters:\n",
        "        audio_file (str): Path to the audio file.\n",
        "        sr (int): Sample rate.\n",
        "        n_mfcc (int): Number of Mel-frequency cepstral coefficients (MFCCs) to extract.\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Extracted audio features.\n",
        "    \"\"\"\n",
        "    # Load audio file\n",
        "    y, sr = librosa.load(audio_file, sr=sr)\n",
        "\n",
        "    # Extract MFCC features\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "    # Calculate mean and standard deviation of MFCCs\n",
        "    mfccs_mean = np.mean(mfccs, axis=1)\n",
        "    mfccs_std = np.std(mfccs, axis=1)\n",
        "\n",
        "    # Concatenate mean and standard deviation\n",
        "    features = np.concatenate((mfccs_mean, mfccs_std))\n",
        "\n",
        "    return features\n",
        "\n",
        "# Example usage\n",
        "audio_file = \"example_audio.wav\"\n",
        "features = extract_features(audio_file)\n",
        "print(\"Extracted features shape:\", features.shape)"
      ],
      "metadata": {
        "id": "_uKl8gbgS91k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a graph\n",
        "G = nx.Graph()\n",
        "\n",
        "# Nodes\n",
        "nodes = [0, 1, 1, 0, 0, 1, 1, 1]\n",
        "\n",
        "# Edges\n",
        "edges = [2, 1, 1, 1, 2, 1, 1]\n",
        "\n",
        "# Adjacency List\n",
        "adjacency_list = [[1, 0], [2, 0], [4, 3], [6, 2], [7, 3], [7, 4], [7, 5]]\n",
        "\n",
        "# Global Attribute\n",
        "global_attribute = 0\n",
        "\n",
        "# Add nodes to the graph\n",
        "for node_id, node_value in enumerate(nodes):\n",
        "    G.add_node(node_id, value=node_value)\n",
        "\n",
        "# Add edges to the graph\n",
        "for i, edge_weight in enumerate(edges):\n",
        "    G.add_edge(i, i+1, weight=edge_weight)\n",
        "\n",
        "# Set global attribute\n",
        "G.graph['global'] = global_attribute\n",
        "\n",
        "# Visualize the graph\n",
        "pos = nx.spring_layout(G, seed=42)\n",
        "labels = nx.get_node_attributes(G, 'value')\n",
        "edge_labels = nx.get_edge_attributes(G, 'weight')\n",
        "nx.draw(G, pos, with_labels=True, labels=labels, node_size=2000, node_color='lightblue', font_size=10)\n",
        "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=10)\n",
        "plt.title(\"Sample Graph\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3r4yUbG8AtgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dbpYilQQqAB",
        "outputId": "d3ff0723-46af-4d17-c9c2-248e52b51e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Define labels and map them to integers\n",
        "labels = {\"sports\": 0, \"interview\": 1, \"reporting\": 2, \"debate\": 3}\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer for sequence classification\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(labels))\n",
        "\n",
        "def label_audio(audio_path, transcript):\n",
        "  \"\"\"\n",
        "  Labels an audio clip based on its transcript using a BERT model.\n",
        "\n",
        "  Args:\n",
        "      audio_path: Path to the audio file.\n",
        "      transcript: Text transcript of the audio content.\n",
        "\n",
        "  Returns:\n",
        "      Predicted label (sports, interview, reporting, debate)\n",
        "  \"\"\"\n",
        "\n",
        "  # Preprocess transcript (tokenization)\n",
        "  encoded_transcript = tokenizer(transcript, return_tensors=\"pt\")\n",
        "\n",
        "  # Load audio using torchaudio\n",
        "  waveform, sample_rate = torchaudio.load(audio_path)\n",
        "\n",
        "  # Feature extraction\n",
        "  mel_spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate)(waveform)\n",
        "  extract_features(audio_file, sr=22050, n_mfcc=13, mel_spectrogram)\n",
        "\n",
        "  # Combine transcript and audio features (replace with your feature fusion method)\n",
        "  # This example simply concatenates the transcript and mel spectrogram\n",
        "  combined_features = torch.cat((encoded_transcript[\"input_ids\"], mel_spectrogram), dim=1)\n",
        "\n",
        "  # Make prediction\n",
        "  outputs = model(combined_features)\n",
        "  predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "  # Map prediction back to label\n",
        "  predicted_label = labels[int(predictions.item())]\n",
        "  return predicted_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZQDL9VJEfU6",
        "outputId": "0326f187-6be7-4e9d-8192-b0c769f819ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioTaggingGNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(AudioTaggingGNN, self).__init__()\n",
        "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# Create a PyTorch Geometric Data object\n",
        "data = Data(x=x, edge_index=edge_index)\n",
        "\n",
        "# Initialize the model\n",
        "model = AudioTaggingGNN(input_dim=input_dim, hidden_dim=64, output_dim=10)  # Assuming 10 audio classes\n",
        "\n",
        "# Forward pass\n",
        "output = model(data.x, data.edge_index)\n"
      ],
      "metadata": {
        "id": "ibrwLtVgRIX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_path = \"https://youtu.be/ADnKaougM6M?si=sNzG7M94j4sjs6Bi\"\n",
        "transcript = extract_features()\n",
        "\n",
        "predicted_label = label_audio(audio_path, transcript)\n",
        "print(f\"Transcript: {transcript}\")\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9Bw6XyREoDd",
        "outputId": "22b9f353-971b-4303-db68-a07285e0fd55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcript: it represents colonization of Bloodshed give it back to India I don't see why an Indian child from India has to travel all the way to the UK to look at him just April narinda the the Sikhs the in Punjab who also by the way the the ruler that you mentioned was also a ruler of Lahore so is Pakistan going to have the same effect history please they stole it from the Persian Empire the Empire the Persian Empire so you know can I just say it represents colonization of Bloodshed give it back to India I don't see why an Indian child from India has to travel all the way to the UK to look at it foreign thank you\n",
            "Predicted Label: Debate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_path = \"https://youtu.be/Rv-H6xXiozU?si=BBR2-CQL1a0pf5WH\"\n",
        "transcript = extract_features()\n",
        "\n",
        "predicted_label = label_audio(audio_path, transcript)\n",
        "print(f\"Transcript: {transcript}\")\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzfRqZBwW4sW",
        "outputId": "797d83ec-edaf-4722-d9e7-a55742fa8502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the Tesla Chief Elon Musk has met government officials in Beijing Chinese State media is reporting that the tech entrepreneur is thereby invitation for the promotion of international trade they have discussed data and Technology relating to electric vehicles Tesla has been facing a price war with Chinese brands in the electric vehicle Market it has recently said it will lay off 10% of its Global Workforce we can now speak to our business reporter David wadell who's in The Newsroom so David why is Mr musk in China well Mr musk's challenge is amongst other things that he's trying to sell more units of his Tesla company's full self-driving software that's the smartphones and let me show you this this is uh are by a company called xang motors which produces not only EVS but here you see a flying vehicle and it's also producing its own form of full self-driving software that is designed to compete with Tesla\n",
            "Predicted Label: Interview\n"
          ]
        }
      ]
    }
  ]
}